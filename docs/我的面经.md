# 1. cookie和sesion
Session 的主要作用就是通过服务端记录用户的状态。 典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。

Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。相对来说 Session 安全性更高。如果使用 Cookie 的一些敏感信息不要写入 Cookie 中，最好能将 Cookie 信息加密然后使用到的时候再去服务器端解密。

那么，如何使用Session进行身份验证？

很多时候我们都是通过 SessionID 来实现特定的用户，SessionID 一般会选择存放在 Redis 中。举个例子：用户成功登陆系统，然后返回给客户端具有 SessionID 的 Cookie，当用户向后端发起请求的时候会把 SessionID 带上，这样后端就知道你的身份状态了。

用户向服务器发送用户名和密码用于登陆系统。  
服务器验证通过后，服务器为用户创建一个 Session，并将 Session信息存储 起来。  
服务器向用户返回一个 SessionID，写入用户的 Cookie。  
当用户保持登录状态时，Cookie 将与每个后续请求一起被发送出去。  
服务器可以将存储在 Cookie 上的 Session ID 与存储在内存中或者数据库中的 Session 信息进行比较，以验证用户的身份，返回给用户客户端响应信息的时候会附带用户当前的状态。

分布式session：  
客户端发送一个请求，经过负载均衡后该请求会被分配到服务器中的其中一个，由于不同服务器含有不同的web服务器(例如Tomcat)，不同的web服务器中并不能发现之前web服务器保存的session信息，就会再次生成一个JSESSIONID，之前的状态就会丢失  
解决方案：session绑定，ip-hash 或者 基于redis存储session

# 2. java线程池
- 降低资源的消耗。线程本身是一种资源，创建和销毁线程会有CPU开销；创建的线程也会占用一定的内存。   

- 提高任务执行的响应速度。任务执行时，可以不必等到线程创建完之后再执行。   
- 提高线程的可管理性。线程不能无限制地创建，需要进行统一的分配、调优和监控。
- ![](figure/threadpool.png)

- 为什么要调用start方法而不是run方法？
    - 调⽤ start ⽅法⽅可启动线程并使线程进⼊就绪状态，⽽ run ⽅法只是 thread 的⼀个普通⽅法调⽤，还是在主线程⾥执⾏。

- 线程池一些参数：
    - corePoolSize: 规定线程池有几个线程(worker)在运行。
    - QUEUE_CAPACITY 队列容量
    - maximumPoolSize: 当workQueue满了,不能添加任务的时候，这个参数才会生效。规定线程池最多只能有多少个线程(worker)在执行。
# 3.影响一个Http服务最大连接数的因素是什么
文件句柄限制:  
执行 ulimit -n 输出 1024，说明对于一个进程而言最多只能打开1024个文件，所以你要采用此默认配置最多也就可以并发上千个TCP连接。
临时修改：ulimit -n 1000000，但是这种临时修改只对当前登录用户目前的使用环境有效，永久修改：编辑/etc/rc.local，在其后添加如下内容：ulimit -SHn 1000000

端口范围限制：客户端端口范围限制。 四元组，服务端实际只使用了bind时这一个端口，说明端口号65535并不是并发量的限制。因此server端tcp连接4元组中只有remote ip（也就是client ip）和remote port（客户端port）是可变的，
因此最大tcp连接为：客户端ip数×客户端port数，对IPV4，不考虑ip地址分类等因素，最大tcp连接数约为：2的32次方（ip数）×2的16次方（port数），也就是server端单机最大tcp连接数约为2的48次方。

# 4.什么是线程安全，线程安全与线程同步。
当多个线程访问某个方法时，不管你通过怎样的调用方式或者说这些线程如何交替的执行，我们在主程序中不需要去做任何的同步，这个类的结果行为都是我们设想的正确行为，那么我们就可以说这个类时线程安全的。
比如 100个线程 i++ 如果不加锁啥的 就是线程不安全的。

线程同步：多个线程操作一个资源的情况下，导致资源数据前后不一致。这样就需要协调线程的调度，即线程同步。 解决多个线程使用共通资源的方法是：线程操作资源时独占资源，其他线程不能访问资源。使用锁可以保证在某一代码段上只有一条线程访问共用资源。

(1)使用synchronized关键字  修饰方法，修饰代码块，修饰类
(2)使用特殊域变量(volatile)

### 4.1 Java多线程---顺序打印ABC打印10次的实现-三种实现
一、基于Semaphore
二、基于Synchronized
三、基于ReentrantLock
https://www.jianshu.com/p/b036dda3f5c8



# 美团 8.10 1面
### 1.InnoDB一棵b+树可以存储多少数据？
一、InnoDB一棵B+树可以存放多少行数据？(约2千万)

我们都知道计算机在存储数据的时候，有最小存储单元，这就好比我们今天进行现金的流通最小单位是一毛。在计算机中磁盘存储数据最小单元是扇区，一个扇区的大小是512字节，而文件系统（例如XFS/EXT4）他的最小单元是块，一个块的大小是4k，而对于我们的InnoDB存储引擎也有自己的最小储存单元——页（Page），一个页的大小是16K。

这里我们先假设B+树高为2，即存在一个根节点和若干个叶子节点，那么这棵B+树的存放总记录数为：根节点指针数*单个叶子节点记录行数。

上文我们已经说明单个叶子节点（页）中的记录数=16K（一页16KB）/1K（假设一行1KB）=16。（这里假设一行记录的数据大小为1k）。

 

那么现在我们需要计算出非叶子节点能存放多少指针？

其实这也很好算，我们假设主键ID为bigint类型，长度为8字节，而指针大小在InnoDB源码中设置为6字节，这样一共14字节，我们一个页中能存放多少这样的单元，其实就代表有多少指针，即16KB（16*1024=16384 byte）16384/14=1170（索引个数）。那么可以算出一棵高度为2的B+树，能存放1170 * 16=18720条这样的数据记录。

 

根据同样的原理我们可以算出一个高度为3的B+树可以存放：1170（索引个数）*1170（索引个数）*16（每页行数）=21902400（2千万）条这样的记录。

所以在InnoDB中B+树高度一般为1-3层，它就能满足千万级的数据存储。在查找数据时一次页的查找代表一次IO，所以通过主键索引查询通常只需要1-3次IO操作即可查找到数据。
### 2.linux内核之扇区,页,块的理解

页：操作系统必须以页为单位管理内存. 一般4k

块:文件系统最小寻址单元,又称为文件块和io块  一般4k

扇区:块设备中最小寻址单元是扇区,扇区这一术语在内核中重要是因为所有设备的io必须以扇区为单位操作


### 3. redis分布式锁，解锁的注意事项。

首先，为了确保分布式锁可用，我们至少要确保锁的实现同时满足以下四个条件：

1. 互斥性。在任意时刻，只有一个客户端能持有锁。
2. 不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。
3. 具有容错性。只要大部分的Redis节点正常运行，客户端就可以加锁和解锁。
4. 解铃还须系铃人。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了。

比较好的实现：
https://blog.csdn.net/kongmin_123/article/details/82080962?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.channel_param
1. set 和 expire 保证原子性。
2. 可以在加锁的时候把当前的线程ID当做value，并在删除之前验证key对应的value是不是自己线程的ID。这样做又隐含了一个新的问题，判断和释放锁是两个独立操作，不是原子性的。
要想实现验证和删除过程的原子性，可以使用Lua脚本来实现。这样就能保证验证和删除过程的正确性了。


redis分布式锁的key可以分段来加，提高并发。
### 4. redis主从复制，哨兵，集群。
redis主从过程
![](figure/redismasterslave.png)
redis哨兵
![](figure/redissentinel.png)
上图 展示了一个典型的哨兵架构图，它由两部分组成，哨兵节点和数据节点：

哨兵节点： 哨兵系统由一个或多个哨兵节点组成，哨兵节点是特殊的 Redis 节点，不存储数据；
数据节点： 主节点和从节点都是数据节点；
在复制的基础上，哨兵实现了 自动化的故障恢复 功能，下方是官方对于哨兵功能的描述：

监控（Monitoring）： 哨兵会不断地检查主节点和从节点是否运作正常。

自动故障转移（Automatic failover）： 当 主节点 不能正常工作时，哨兵会开始 自动故障转移操作，它会将失效主节点的其中一个 从节点升级为新的主节点，并让其他从节点改为复制新的主节点。

配置提供者（Configuration provider）： 客户端在初始化时，通过连接哨兵来获得当前 Redis 服务的主节点地址。

通知（Notification）： 哨兵可以将故障转移的结果发送给客户端。
其中，监控和自动故障转移功能，使得哨兵可以及时发现主节点故障并完成转移。而配置提供者和通知功能，则需要在与客户端的交互中才能体现。

简单来说 Sentinel 使用以下规则来选择新的主服务器：

在失效主服务器属下的从服务器当中， 那些被标记为主观下线、已断线、或者最后一次回复 PING 命令的时间大于五秒钟的从服务器都会被 淘汰。  
在失效主服务器属下的从服务器当中， 那些与失效主服务器连接断开的时长超过 down-after 选项指定的时长十倍的从服务器都会被 淘汰。  
在 经历了以上两轮淘汰之后 剩下来的从服务器中， 我们选出 复制偏移量（replication offset）最大 的那个 从服务器 作为新的主服务器；如果复制偏移量不可用，或者从服务器的复制偏移量相同，那么 带有最小运行 ID 的那个从服务器成为新的主服务器。
redis集群
![](figure/rediscluster.png)


![](figure/yizhixinghash.png)
集群数据分区方案 

方案一：哈希值 % 节点数
哈希取余分区思路非常简单：计算 key 的 hash 值，然后对节点数量进行取余，从而决定数据映射到哪个节点上。

不过该方案最大的问题是，当新增或删减节点时，节点数量发生变化，系统中所有的数据都需要 重新计算映射关系，引发大规模数据迁移。

方案二：一致性哈希分区
一致性哈希算法将 整个哈希值空间 组织成一个虚拟的圆环，范围是 [0 , 232-1]，对于每一个数据，根据 key 计算 hash 值，确数据在环上的位置，然后从此位置沿顺时针行走，找到的第一台服务器就是其应该映射到的服务器：
与哈希取余分区相比，一致性哈希分区将 增减节点的影响限制在相邻节点。以上图为例，如果在 node1 和 node2 之间增加 node5，则只有 node2 中的一部分数据会迁移到 node5；如果去掉 node2，则原 node2 中的数据只会迁移到 node4 中，只有 node4 会受影响。

一致性哈希分区的主要问题在于，当 节点数量较少 时，增加或删减节点，对单个节点的影响可能很大，造成数据的严重不平衡。还是以上图为例，如果去掉 node2，node4 中的数据由总数据的 1/4 左右变为 1/2 左右，与其他节点相比负载过高。

方案三：带有虚拟节点的一致性哈希分区

非常明显，把这个环上的槽点弄的密集一点，那这样，宕机几个节点，就分配到其他节点比较均衡。

该方案在 一致性哈希分区的基础上，引入了 虚拟节点 的概念。Redis 集群使用的便是该方案，其中的虚拟节点称为 槽（slot）。槽是介于数据和实际节点之间的虚拟概念，每个实际节点包含一定数量的槽，每个槽包含哈希值在一定范围内的数据。

在使用了槽的一致性哈希分区中，槽是数据管理和迁移的基本单位。槽 解耦 了 数据和实际节点 之间的关系，增加或删除节点对系统的影响很小。仍以上图为例，系统中有 4 个实际节点，假设为其分配 16 个槽(0-15)；

槽 0-3 位于 node1；4-7 位于 node2；以此类推....
如果此时删除 node2，只需要将槽 4-7 重新分配即可，例如槽 4-5 分配给 node1，槽 6 分配给 node3，槽 7 分配给 node4；可以看出删除 node2 后，数据在其他节点的分布仍然较为均衡。

https://github.com/Snailclimb/JavaGuide/blob/master/docs/database/Redis/redis-collection/Redis(9)%E2%80%94%E2%80%94%E9%9B%86%E7%BE%A4%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5%E6%95%99%E7%A8%8B.md
### 5. 写个伪代码：如何把请求的url映射到Controller层方法上

### 6. epoll的两种模式 -- 水平和边沿

LT:level trigger, 水平触发模式  ET:edge trigger, 边缘触发模式相同点

两种模式LT和ET：最后看看epoll独有的两种模式LT和ET。无论是LT和ET模式，都适用于以上所说的流程。区别是，LT模式下，只要一个句柄上的事件一次没有处理完，会在以后调用epoll_wait时次次返回这个句柄，而ET模式仅在第一次返回。
这件事怎么做到的呢？当一个socket句柄上有事件时，内核会把该句柄插入上面所说的准备就绪list链表，这时我们调用epoll_wait，会把准备就绪的socket拷贝到用户态内存，然后清空准备就绪list链表，最后，epoll_wait干了件事，就是检查这些socket，如果是LT模式，并且这些socket上确实有未处理的事件时，又把该句柄放回到刚刚清空的准备就绪链表了。所以，LT的句柄，只要它上面还有事件，epoll_wait每次都会返回。而ET模式的句柄，除非有新中断到，即使socket上的事件没有处理完，也是不会次次从epoll_wait返回的。


### 7. hashmap中如何判断两个对象相同。
先判断hashcode相同不，不相同肯定不是一个。相同的话，再判断equals。
不同对象可能会有相同的hashcode，哈希冲突。 如何判断是究竟是两个逻辑相等的对象重复写入，还是两个逻辑不等的对象出现了哈希冲突呢？
所以，要判断一下，equals相同不。

### 8.线程池有哪些参数，执行流程是怎样的？有哪些常用 BlockingQueue，区别是什么？拒绝策略有哪些？shutdown() 和 shutdownNow() 有什么区别？

### 9. synchronized 和 ReentrantLock 区别？ReentrantLock 实现原理，AQS 原理，CountdownLatch 和 Semaphore 的作用？

### 10. 说一说在浏览器中输入一个url后，直到浏览器显示页面的过程中发生了什么？

# 2. 腾讯音乐人1面 8.15晚7.30
- 不会的问题，慢慢来，别着急，别慌，稳点！

- 1.数据结构里面的树全介绍一遍，二叉树出来的背景，以及可以解决的问题。
Java里的集合啊，mysql的索引啊。
    - 树- 搜索树，平衡树，红黑树（也是一种平衡树），b树，b+树。 （红黑树，AVL树都是有序的）， LSM Tree
    - 平衡树： AVL的每一次插入结点操作最多只需要旋转1次(单旋转或双旋转)，删除之后必须检查从删除结点开始到根结点路径上的所有结点的平衡因子。因此删除的代价稍微要大一些。每一次删除操作最多需要O(logN)次旋转
    
    - 红黑树： 最长路径不超过最短路径的两倍就可以，每个红节点下面跟个黑节点，每条链路上黑节点个数必须相同。插入最多两次旋转，删除最多三次旋转。
    - AVL树和红黑树区别？
        - AVL树是高度平衡的，每插入和删除很大概率就需要进行左旋右旋操作来恢复平衡。
        - 红黑树不是高度平衡的，每次插入和删除要rebalance的概率比AVL树低。 而且变色操作很简单快速。
    - b树，b+树： B+树更适合文件系统的磁盘存储结构，减少磁盘io次数，每个树节点可以存很多索引，通过2-3次的磁盘io就可以找到所查找的数据。
    - b+树相对于b树有一些自己的优势，可以归结为下面几点。
        - 单一节点存储的元素更多（一个节点为innodb定义的一页，16k），使得查询的IO次数更少，所以也就使得它更适合做为数据库MySQL的底层数据结构了。
        
        - 所有的查询都要查找到叶子节点，查询性能是稳定的，而B树，每个节点都可以查找到数据，所以不稳定。
        - 所有的叶子节点形成了一个有序链表，更加便于查找
        - https://blog.csdn.net/zl1zl2zl3/article/details/88321108
        
    - LSM Tree
        - https://blog.csdn.net/mingyuezh/article/details/80839868
        - 面试回答：
            - 比如说 随机插入数据，或者随机读取数据， b+树随机磁盘io浪费资源。
            而lsm树可以顺序写入内存中，然后刷到磁盘上，写效率很高。读的时候，依靠内存命中率，内存读不到，去各个小树找，各个小树有序，
            不断的合并这些小树。
        - lsm tree牺牲部分读性能，而大幅度提高写性能。 读多写少b+树，因为大量写大量随机io要分裂树节点。 写多lsm tree，内存中写，非常块。
        - 原理是把一颗大树拆分成N棵小树， 它首先写入到内存中（内存没有寻道速度的问题，随机写的性能得到大幅提升），在内存中构建一颗有序小树，随着小树越来越大，内存的小树会flush到磁盘上。当读时，由于不知道数据在哪棵小树上，因此必须遍历所有的小树，但在每颗小树内部数据是有序的。

        - 以上就是LSM树最本质的原理，有了原理，再看具体的技术就很简单了。
            - 1）首先说说为什么要有WAL（Write Ahead Log），很简单，因为数据是先写到内存中，如果断电，内存中的数据会丢失，因此为了保护内存中的数据，需要在磁盘上先记录logfile，当内存中的数据flush到磁盘上时，就可以抛弃相应的Logfile。
            - 2）什么是memstore, storefile？很简单，上面说过，LSM树就是一堆小树，在内存中的小树即memstore，每次flush，内存中的memstore变成磁盘上一个新的storefile。
            - 3）为什么会有compact？很简单，随着小树越来越多，读的性能会越来越差，因此需要在适当的时候，对磁盘中的小树进行merge，多棵小树变成一颗大树。
- 2.Treemap是什么实现的？  --红黑树，所以添加，删除，查找效率都比HashMap低，但是key有序。
- 3.其他能够实现红黑树特性的数据结构？ -- 跳表
    - Skip List主要思想是将链表与二分查找相结合，以空间换时间
    
    - 跳表和红黑树的区别？
        - 跳表实现简单
        
        - 进行范围查找效率高（最下层有链表），而红黑树等还要用中序遍历去查找其他节点。
        - 红黑树的插入删除，需要rebalance，而跳表只需要修改相邻节点的指针。
    - 跳表有什么缺点？
        - 虽然每个节点占用的空间要小一些，skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。但是要向上抽取节点建多层索引，占内存更多一些。  
    - 占的空间多一些，为什么呢？ 空间换时间
    - 跳表怎么去找一些节点往上层抽，抽的节点，有什么讲究？比如要是抽的节点都排在一起，肯定不合理。
        - Skip List还有一个明显的特征，即它是一个不准确的概率性结构，这是因为Skip List在决定是否将节点冗余复制到上一层的时候（而在到达或超过顶层时，需要构建新的顶层）依赖于一个概率函数，举个栗子，我们使用一个最简单的概率函数：丢硬币，即概率P为0.5，那么依赖于该概率函数实现的Skip List会不断地"丢硬币"，如果硬币为正面就将节点复制到上一层，直到硬币为反。
        - 抛硬币算法，随机决定插入的新节点是否向上提拔，每向上提拔一层的概率是50%。
    - 具体的一些算法，redis里面sort set看一下怎么抽的节点。
        - sorted set 也是抛硬币决定是不是向上抽的。
- 4.Java的项目，秒杀系统，大概讲一下？
    - 核心思路是通过缓存，异步，限流来保证系统的高并发和高可用。
    
    - 库存放到redis里缓存，用分布式锁防止超卖。
    - redis减库存后，将用户信息，订单信息，放到消息队列中做削峰，异步。
    - 前端限流，后端限流redis计数器做限流。

- 5.Synchronized 偏向锁，轻量级锁，讲一下？
    - https://blog.csdn.net/zqz_zqz/article/details/70233767
    - 先看markword里的锁标志是不是为偏向锁标志，是的话，检查对象markword里是否存着当前线程ID，如果是的话，就执行同步代码。不是的话，尝试用CAS将markword里的线程ID改为当前线程ID。
    如果成功，将markword里的线程ID改为当前线程ID，执行同步代码。如果失败，表示有竞争，到达全局安全点后，已获得偏向锁的线程被挂起，升级为轻量级锁，阻塞在安全点的线程继续往下执行同步代码。
    - 偏向锁适用于只有一个线程在执行同步块，无锁竞争的情况下使用。一旦有竞争就升级为轻量级锁。
    
    - 轻量级锁：代码进入同步块之前，如果对象头里是无锁状态，虚拟机会在当前线程的栈帧中创建一个锁记录（Lock record）的空间，
    用于存储markword的拷贝，之后虚拟机使用CAS操作将对象的markword更新为指向Lock record的指针，并将Lock record里的owner指向对象头的mark word。
    如果成功，表示该线程拥有了该对象的锁，将对象头的锁标志位设置为00，表示该对象处于轻量级锁状态。
    如果失败，虚拟机会检查对象头是不是指向当前线程的线程的栈帧，如果是表示当前线程已经拥有了这个对象的锁，可以执行同步代码块了。
    否则说明多个线程竞争锁，要升级为重量级锁。锁标志位改为10.Mark word里存的就是指向重量级锁的指针。后面等待锁的线程要进入阻塞状态。
    当前线程尝试使用自旋来获得锁。
    
    - 由轻量锁切换到重量锁，是发生在轻量锁释放锁的期间，之前在获取锁的时候它拷贝了锁对象头的markword，在释放锁的时候如果它发现在它持有锁的期间有其他线程来尝试获取锁了，并且该线程对markword做了修改，两者比对发现不一致，则切换到重量锁。
        - ![](figure/qingsuo.png)
        - ![](figure/qingsuo2.png)
    - synchronized的执行过程：
        - 1.检测Mark Word里面是不是当前线程的ID，如果是，表示当前线程处于偏向锁
        - 2.如果不是，则使用CAS将当前线程的ID替换Mard Word，如果成功则表示当前线程获得偏向锁，置偏向标志位1
        - 3.如果失败，则说明发生竞争，撤销偏向锁，进而升级为轻量级锁。
        - 4.当前线程使用CAS将对象头的Mark Word替换为锁记录指针，如果成功，当前线程获得锁
        - 5.如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。
        - 6.如果自旋成功则依然处于轻量级状态。
        - 7.如果自旋失败，则升级为重量级锁。


- 6.Linux相关
    - 查看数据库与服务建立的连接？
        - netstat -nat | grep 数据库ip
    
    - grep里有很多参数知道哪些？
        - grep -A2 就是查关键字的后两行，after意思
        - grep -B2 查关键字的前两行
        - grep -C2 前后都看
        - grep -a就是需要排除这个关键字的结果。
        - grep -c就是统计error日志的出现次数。
    - sed和awt了解吗？？？
- 7.有去了解过一些框架吗？springboot啊？了解吗？
- 8.看过设计模式或者软件源码吗？
- 9.TCP为什么四次挥手，3次握手？
- 10.2MSL一般是多少，linux里面一般是多少，这个东西可以调吗？
    - https://blog.csdn.net/xiaofei0859/article/details/6044694
   
    - 这个生存时间是由源主机设置初始值但不是存的具体时间，而是存储了一个ip数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减1，当此值为0则数据报将被丢弃，同时发送ICMP报文通知源主机。RFC 793中规定MSL为2分钟，实际应用中常用的是30秒，1分钟和2分钟等。
    - 为什么是2倍呢？
    - close-wait是什么情况下出现的？
- 11.tcp里面滑动窗口用来干嘛的？
    
    - 滑动窗口的窗口大小是怎么确定的？
- 12.tcp为什么会出现拆包粘包的问题？
    - 业内如何处理粘包，拆包？
    - 头部放入包的大小？
    - 末尾加特殊标示，有什么缺点？
- 13.看过java里的io吗？
    - 讲一下多路复用的原理？
- 14.想去快速知道腾讯员工里面重名的有多少？用sql来写？
    - select name from student group_by name haven  count(*)>1 这个就可以 了解下 haven
- 15.前中后序遍历，不用递归，怎么做？ 可以用for循环+栈
- 16.es相关
    - Es里的路由节点和数据节点的区别？
    - 为什么用ES？
    - Es分布式的，查一条数据，数据可能在不同的节点上，es如何处理。
    - 归并排序，对所有分片读到 查询节点的 5000 10，做归并排序查询。

# 3. 美团二面
1.	算法题：
数组里找到第m小的元素，并打印出来
在n个数字里随机的选出m个数，这m个数字不可以重复。任何一个数字只能选中1次。1 2 3 4 5 里面数字1只能选1次。
一段文本中，输入一个文本串，输出最长重复子串。 后缀树？前缀树？
2．两个进程，c语言对地址进行赋值，是逻辑地址吧？  是的
3. 进程内存隔离吗？ 不同进程内存隔离，为什么又有共享内存呢？怎么做到既可以隔离又可以共享？
   - 虚拟内存让进程认为自己独有一段连续的空间，页表将俩块逻辑地址映射到同一块物理地址，就共享内存了。
4. Mmu是什么？
    - CPU访问地址是向MMU发送地址，然后从MMU获得数据，虚拟地址经过MMU转化为物理地址，从而访问外部内存里的数据。
    - MMU就是将逻辑地址查页表，然后返回物理地址。
5. 内存映射 段式，页式？
    - 共享内存可以通过mmap()映射普通文件机制实现
6. TCP协议，可靠，是说发了一个之后，接收端一定能收到吗？会有收不到的情况吗？
    - 可靠，指 发送发的 一定和接收端接受的一样。按序，完整的收到。
    - 收不到 就超时重传
7. 可能是什么原因没有收到第一次发的数据包呢？
    - 丢包
    - 接收方由于缓存溢出，导致无法再处理到来的数据包了，直接丢弃从而造成丢包
    - 网络拥塞导致数据包丢包
    - 数据包被检测到损坏了，被接收方丢弃造成了丢包
8. 丢包可能会在哪个地方丢？怎么丢？为什么会丢包？
    - 网络链接阻塞
    - 路由器设备性能
    https://blog.csdn.net/duandianR/article/details/77513506
9. ip层为啥会丢包？
    - 不可靠呀
10． 路由器那块是不是可能也会丢？
    - 会
11. 路由器为什么会丢？
    - 网络设备cpu或者内存满了，来不及出来，丢
12. 可靠表现在哪些方面？
13. 拥塞控制怎么保证可靠性？
14. select * from student where age>18 and score=90 order by ip
(score, age) 这个索引， 那这个语句会用到索引吗？

# 4. 腾讯二面
1. LSM树和b+树的区别？
    - 比如说 随机插入数据，或者随机读取数据， b+树随机磁盘io浪费资源。
    而lsm树可以顺序写入内存中，然后刷到磁盘上，写效率很高。读的时候，依靠内存命中率，内存读不到，去各个小树找，各个小树有序，
    不断的合并这些小树。
2. 介绍下秒杀系统，哪里最难
    - 秒杀接口，要限流，缓存，异步
3. 秒杀场景Redis和mysql数据同步
    - 这种业务场景，不需要数据一致，都在redis里操作
4. Redis挂了怎么办
    - 主从，集群，高可用
5. 异步一般通过什么方式来实现？
6. 多线程，进程内的线程，如何传递消息？  有数据了，通过对方去拿数据？
    - 全局变量 wait notify
    
- wait notify 底层？

7. 多个线程能够在某一个时刻可以同时触发。
    - CyclicBarrier （适用在多线程相互等待，直到到达一个屏障点。
    - CountDownLatch 实现，CountDownLatch可以理解为一个计数器，直到计数器为0了，等待的线程才执行。
    - https://www.jianshu.com/p/892aa4af8b8e
8. Zset的业务场景，
    - 游戏排名、微博热点话题
9. Kafka的分区选多少个分区？
    - kafka分区过多的缺点？
    - https://www.cnblogs.com/chong-zuo3322/p/13523525.html
    - 文件句柄开销大
        - 每个分区在底层文件系统都有属于自己的一个目录。该目录下通常会有两个文件： base_offset.log和base_offset.index。Kafak的controller和ReplicaManager会为每个broker都保存这两个文件句柄(file handler)。很明显，如果分区数越多，所需要保持打开状态的文件句柄数也就越多，最终可能会突破你的ulimit -n的限制。
    
    - 降低高可用性
        - Kafka通过副本(replica)机制来保证高可用。具体做法就是为每个分区保存若干个副本(replica_factor指定副本数)。每个副本保存在不同的broker上。

10. Kafka如何高可用，保证机器挂了数据不会丢失。
    - Kafka通过副本(replica)机制来保证高可用。具体做法就是为每个分区保存若干个副本(replica_factor指定副本数)。每个副本保存在不同的broker上。期中的一个副本充当leader 副本，负责处理producer和consumer请求。其他副本充当follower角色，由Kafka controller负责保证与leader的同步。如果leader所在的broker挂掉了，contorller会检测到然后在zookeeper的帮助下重选出新的leader
11. Kafka怎么保证，写的数据能够到replica里？
    - Follower在收到该消息并写入其Log后，向Leader发送ACK。一旦Leader收到了ISR中的所有Replica的ACK，该消息就被认为已经commit了，Leader将增加HW并且向Producer发送ACK。

12. 平时通过什么学习新知识？

13. 平时学习工作中接触到一个新的概念，通过什么方式去上手学习。

14.	有没有看过一些源码？

15.	有去阅读过一些技术介绍的书吗？

16.	举个例子，最近看的书？

17.	对以后的职业规划？
