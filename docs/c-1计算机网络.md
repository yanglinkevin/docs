# 1.bio nio select poll epoll
阻塞io 就是说 accept 或者 receiv的时候，如果客户端没准备好，那就会阻塞住。所以需要 一个客户端对应一个线程去处理。  非阻塞的话，就是说，可以用一个线程去处理这么多的连接。每次都去循环遍历这些文件描述符，如果有一万个链接，那就是一万次系统调用，非常耗时。 
tips： 阻塞的时候不占用CPU，CPU已经就交出去了。 非阻塞比如Whie(1)这个是一直占用CPU的。
https://juejin.im/post/5eb8e318f265da7bbd2f9339
多路复用，就是说 会有一个线程，去监控这些文件描述符，当其中有准备好的，就再进行读取就可以了。不用遍历，是事件驱动的。
select 就是 每次都要从用户态把 所有的文件描述符传到内核态，然后内核态再遍历这些文件描述符，把所有准备好的 文件描述符返回给用户态。 用户态再进行读写操作。 注意： 这里是内核态遍历o（n），而非阻塞io是发生了 o（n）次的系统调用。   而epoll是在内核态维护了一个数据结构，每次增加或者删除 文件描述符 只传一次给内核态就可以了！ 并且 内核态不需要每次都遍历所有的文件描述符，基于事件驱动，这些文件描述符 有哪个准备好了，会挂载到另一个链表数据结构上！ 用户进程再去链表中去拿准备好的文件描述符就可以了！！！！

简而言之， select 就是每次把fdset（rset， 一个bitmap 1024位）传到内核态。然后内核态进行遍历，看对应的fd是否有事件到达，当没有的时候，就会阻塞住，select会阻塞在那一行，内核态会一直在里面进行判断。让有了一个或者多个事件到达，把对应rset置位并立马返回，这个时候 用户态再去遍历一次 fdset对应的rset是否被置位，若置位了，则进行对应的读写操作。之后，再把fdset对应的rset重新置位回原来的样子，然后再传到内核态。

poll的话 和select区别就是 少了1024限制，然后不需要再遍历一次 将fdset重新置位了，而是在读处理的时候 直接将reevents置回0了。

epoll的高效：
epoll的高效就在于，当我们调用epoll_ctl往里塞入百万个句柄时，epoll_wait仍然可以飞快的返回，并有效的将发生事件的句柄给我们用户。这是由于我们在调用epoll_create时，内核除了帮我们在epoll文件系统里建了个file结点，在内核cache里建了个红黑树用于存储以后epoll_ctl传来的socket外，还会再建立一个list链表，用于存储准备就绪的事件，当epoll_wait调用时，仅仅观察这个list链表里有没有数据即可。有数据就返回，没有数据就sleep，等到timeout时间到后即使链表没数据也返回。所以，epoll_wait非常高效。
就绪list链表维护：
那么，这个准备就绪list链表是怎么维护的呢？当我们执行epoll_ctl时，除了把socket放到epoll文件系统里file对象对应的红黑树上之外，还会给内核中断处理程序注册一个回调函数，告诉内核，如果这个句柄的中断到了，就把它放到准备就绪list链表里。所以，当一个socket上有数据到了，内核在把网卡上的数据copy到内核中后就来把socket插入到准备就绪链表里了。
如此，一颗红黑树，一张准备就绪句柄链表，少量的内核cache，就帮我们解决了大并发下的socket处理问题。执行epoll_create时，创建了红黑树和就绪链表，执行epoll_ctl时，如果增加socket句柄，则检查在红黑树中是否存在，存在立即返回，不存在则添加到树干上，然后向内核注册回调函数，用于当中断事件来临时向准备就绪链表中插入数据。执行epoll_wait时立刻返回准备就绪链表里的数据即可。
两种模式LT和ET：
最后看看epoll独有的两种模式LT和ET。无论是LT和ET模式，都适用于以上所说的流程。区别是，LT模式下，只要一个句柄上的事件一次没有处理完，会在以后调用epoll_wait时次次返回这个句柄，而ET模式仅在第一次返回。
这件事怎么做到的呢？当一个socket句柄上有事件时，内核会把该句柄插入上面所说的准备就绪list链表，这时我们调用epoll_wait，会把准备就绪的socket拷贝到用户态内存，然后清空准备就绪list链表，最后，epoll_wait干了件事，就是检查这些socket，如果不是ET模式（就是LT模式的句柄了），并且这些socket上确实有未处理的事件时，又把该句柄放回到刚刚清空的准备就绪链表了。所以，非ET的句柄，只要它上面还有事件，epoll_wait每次都会返回。而ET模式的句柄，除非有新中断到，即使socket上的事件没有处理完，也是不会次次从epoll_wait返回的。

####实例代码
```c
define MAX_EVENTS 10
int main() {
	struct epoll_event ev, events[MAX_EVENTS];
    int listen_sock, conn_sock, nfds, epollfd;

    /* Code to set up listening socket, 'listen_sock',
     (socket(), bind(), listen()) omitted */

	epollfd = epoll_create1(0);
	if (epollfd == -1) {
		perror("epoll_create1");
      	exit(EXIT_FAILURE);
	}

	ev.events = EPOLLIN;
	ev.data.fd = listen_sock;
	if (epoll_ctl(epollfd, EPOLL_CTL_ADD, listen_sock, &ev) == -1) {
		perror("epoll_ctl: listen_sock");
		exit(EXIT_FAILURE);
	}

	for (;;) {
	    // 永久阻塞，直到有事件
		nfds = epoll_wait(epollfd, events, MAX_EVENTS, -1);
		if (nfds == -1) {  // 处理错误
			perror("epoll_wait");
			exit(EXIT_FAILURE);
		}

		for (n = 0; n < nfds; ++n) {
			if (events[n].data.fd == listen_sock) {
				conn_sock = accept(listen_sock, (struct sockaddr *) &addr, &addrlen);
				if (conn_sock == -1) {
					perror("accept");
					exit(EXIT_FAILURE);
				}
				setnonblocking(conn_sock);
				ev.events = EPOLLIN | EPOLLET;
				ev.data.fd = conn_sock;
				if (epoll_ctl(epollfd, EPOLL_CTL_ADD, conn_sock, &ev) == -1) {
					perror("epoll_ctl: conn_sock");
					exit(EXIT_FAILURE);
				}
			} else {
				do_use_fd(events[n].data.fd);
			}
		}
	}
	return 0;
}
```

#2.三次握手，四次挥手
![](figure/threehands.jpg)
![](figure/fourhands.jpg)
##2.1 close_wait过多的原因
close_wait 按照正常操作的话应该很短暂的一个状态，接收到客户端的fin包并且回复客户端ack之后，会继续发送fin包告知客户端关闭关闭连接，之后迁移到Last_ACK状态。但是close_wait过多只能说明没有迁移到Last_ACK，也就是服务端是否发送fin包，只有发送fin包才会发生迁移，所以问题定位在是否发送fin包。fin包的底层实现其实就是调用socket的close方法，这里的问题出在没有执行close方法。说明服务端socket忙于读写。


CLOSE_WAIT是被动关闭连接时形成的。根据TCP状态机，服务器端收到客户端发送的FIN，则按照TCP实现发送ACK，因此进入CLOSE_WAIT状态。但如果服务器端不执行close()，就不能由CLOSE_WAIT迁移到LAST_ACK，则系统中会存在很多CLOSE_WAIT状态的连接。此时，可能是系统忙于处理读、写操作，而未将已收到FIN的连接，进行close。此时，recv/read已收到FIN的连接socket，会返回0。

##2.2 TIME_WAIT 和CLOSE_WAIT状态socket过多
如果服务器出了异常，百分之八九十都是下面两种情况：

1.服务器保持了大量TIME_WAIT状态

2.服务器保持了大量CLOSE_WAIT状态，简单来说CLOSE_WAIT数目过大是由于被动关闭连接处理不当导致的。

因为linux分配给一个用户的文件句柄是有限的，而TIME_WAIT和CLOSE_WAIT两种状态如果一直被保持，那么意味着对应数目的通道就一直被占着，而且是“占着茅坑不使劲”，一旦达到句柄数上限，新的请求就无法被处理了，接着就是大量Too Many Open Files异常，Tomcat崩溃。

##2.3 为什么 TIME_WAIT 状态需要保持 2MSL 这么长的时间？

如果 TIME_WAIT 状态保持时间不足够长(比如小于2MSL)，第一个连接就正常终止了。第二个拥有相同相关五元组的连接出现，而第一个连接的重复报文到达，干扰了第二个连接。TCP实现必须防止某个连接的重复报文在连接终止后出现，所以让TIME_WAIT状态保持时间足够长(2MSL)，连接相应方向上的TCP报文要么完全响应完毕，要么被 丢弃。建立第二个连接的时候，不会混淆。

1.为了防止最后一个ACK没有送到服务端，如果客户端立即关闭的话，服务端会重新发fin包，这时客户端关闭，服务端会收到RST，也就是一个报错
2.为了防止当前连接中的重复报文干扰下一个连接

# 3. HTTP1.0 1.1 2.0的区别
## 3.1HTTP1.0 HTTP 1.1主要区别
（1）长连接

HTTP 1.0需要使用keep-alive参数来告知服务器端要建立一个长连接，而HTTP1.1默认支持长连接。

HTTP是基于TCP/IP协议的，创建一个TCP连接是需要经过三次握手的,有一定的开销，如果每次通讯都要重新建立连接的话，对性能有影响。因此最好能维持一个长连接，可以用个长连接来发多个请求。

（2）节约带宽

HTTP 1.1支持只发送header信息(不带任何body信息)，如果服务器认为客户端有权限请求服务器，则返回100，否则返回401。客户端如果接受到100，才开始把请求body发送到服务器。

这样当服务器返回401的时候，客户端就可以不用发送请求body了，节约了带宽。

另外HTTP还支持传送内容的一部分。这样当客户端已经有一部分的资源后，只需要跟服务器请求另外的部分资源即可。这是支持文件断点续传的基础。

（3) HOST域

##3.2HTTP1.1 HTTP 2.0主要区别
(1)多路复用

HTTP2.0使用了多路复用的技术，做到同一个连接并发处理多个请求，而且并发请求的数量比HTTP1.1大了好几个数量级。

当然HTTP1.1也可以多建立几个TCP连接，来支持处理更多并发的请求，但是创建TCP连接本身也是有开销的。

TCP连接有一个预热和保护的过程，先检查数据是否传送成功，一旦成功过，则慢慢加大传输速度。因此对应瞬时并发的连接，服务器的响应就会变慢。所以最好能使用一个建立好的连接，并且这个连接可以支持瞬时并发的请求。

![](figure/http.png)
这个图可以很清楚的看出，1.0是一个请求 就连接 然后 断开连接， 1.1是一个连接 可以对应多个请求，但是请求是有顺序的，第二个请求必须等第一个请求结束才可以发送， 2.0是 client 端就可以在一个链接中并发地发起多个请求，每个请求及该请求的响应不需要等待其他的请求。

(2)数据压缩

(3)服务器推送
https://blog.csdn.net/linsongbin1/article/details/54980801?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param

#4.各层协议的作用，以及TCP/IP协议的特点
![](figure/net.jpg)
传输层是报文段 网络层是数据报 链路层是数据帧

1.数据链路层  

1.1 作用  
(1) 实现网卡接口的网络驱动，以处理数据在以太网线等物理媒介上的传输  
(2) 网络驱动程序隐藏了不同物理网络的不同电气特性，为上层协议提供一个统一的接口

1.2 协议应用  
ARP和RARP(Reverse Address Resolve Protocol)即逆地址解析协议，该协议实现了IP地址和物理地址(MAC地址)之间的转换。ARP首先会发起一个请求数据包，数据包的首部包含了目标主机的IP地址，然后这个数据包会在链路层进行再次包装，生成以太网数据包，最终由以太网广播给子网内的所有主机，每一台主机都会接收到这个数据包，并取出标头里的IP地址，然后和自己的IP地址进行比较，如果相同就返回自己的MAC地址，如果不同就丢弃该数据包。ARP接收返回消息，以此确定目标机的MAC地址；与此同时，ARP还会将返回的MAC地址与对应的IP地址存入本机ARP缓存中并保留一定时间，下次请求时直接查询ARP缓存以节约资源。

2.网络层  

2.1 作用  
网络有分局域网(LAN, Local Area Network)和广域网(WAN, Wide Area Network)。对于后者通常需要使用众多分级的路由器来连接分散的主机或者LAN，即通讯的两台主机一般不是直接连接，而是通过多个中间节点(路由器)连接的，从而形成网络拓扑连接。  
(1) 网络层的任务之一就是选择这些中间节点，以确定两台主机间的通讯路径。  
(2) 其次网络层对上层协议隐藏了网络拓扑连接的细节，在使得传输层看来通讯双方是直接连接的

2.2 协议应用  
(1) IP协议: IP协议(Internet Protocol)是网络层最核心的协议，它根据数据包的目的IP地址来决定如何投递该数据包。若数据包不可直接发送给目标主机，那么IP协议就为它寻找一个合适的下一跳路由器，并将数据包交付给该路由器去转发，如此循环直至到达目标主机或者发送失败而丢弃该数据包。  
（1）寻址和路由；（根据对方的IP地址，寻找最佳路径传输信息）；  
（2）传递服务：
① 不可靠（IP协议只是尽自己最大努力去传输数据包），可靠性由上层协议提供（TCP协议）； ② 无连接（事先不建立会话），不维护任何关于后续数据报的信息；  
（3）数据包的分片和重组。

(2) ICMP协议: ICMP协议(Internet Control Message Protocol，因特网控制报文协议)是IP协议的补充，用于检测网络的连接状态，如ping应用程序就是ICMP协议的使用。ICMP包发送是不可靠的，所以不能依靠接收ICMP包解决网络问题；ICMP与TCP/UDP不同，它们是传输层协议，虽然都具有类型域和代码域，但是前者和后者不同，ping用到的ICMP协议，不是端口。ICMP协议使用的是IP协议而非使用下层协议提供的服务，所以严格来讲它并非网络层协议，而是网络层程序。

3.传输层

3.1 作用  
传输层的作用是为应用程序提供端对端通讯的”错觉”，即为应用程序隐藏了数据包跳转的细节，负责数据包的收发、链路超时重连等。

3.2 协议应用  
(1) TCP协议: TCP协议(Transmission Control Protocol, 传输控制协议)为应用程序提供可靠的、面向连接的、基于流的服务，具有超时重传、数据确认等方式来确保数据包被正确发送到目的端。因此TCP服务是可靠的，使用TCP协议通讯的双方必须先建立起TCP连接，并在系统内核中为该连接维持一些必要的数据结构，比如连接的状态，读写缓冲区，多个定时器等。当通讯结束时双方必须关闭连接以释放这些内核数据。基于流发送意思是数据是没有长度限制，它可源源不断地从通讯的一端流入另一端。  
(2) UDP协议: UDP协议(User Datagram Protocol, 用户数据报协议)与TCP协议相反，它为应用程序提供的是不可靠的、无连接的基于数据报的服务。
  无连接: 通讯双方不保持一个长久的联系，因此应用程序每次发送数据都要明确指定接收方的地址；
  基于数据报的服务: 这是相对于数据流而言的，每个UDP数据报都有一个长度，接收端必须以该长度为最小单位将其内容一次性读出，否则数据将被截断。
  UDP不具有发送时是被重发功能，所以UDP协议在内核实现中无需为应用程序的数据保存副本，当UDP数据报被成功发送之后，UDP内核缓冲区中该数据报就被丢弃了。  
(3) SCTP协议: SCTP(Stream Control Transmission Protocol, 流控制传输协议)是为了在因特网上传输电话信号而设计的。

4.应用层  
4.1 作用  
前面所述的三层负责处理网络通讯的相关细节，这部分需要稳定高效，因此它们是在操作系统的内核空间中，而应用层是在用户空间实现的，负责处理众多业务逻辑，如文件传输、网络管理。  
4.2 协议应用  
应用层的协议很多，如：  
(1) telne协议: 远程登录协议，它使我们能在本地完成远程任务  
(2) OSPF协议: OSPF协议(Open Shorttest Path First, 开放最短路径优先)是一种动态路由更新协议，用于路由器之间的通讯，以告知对方自身的路由信息  
(3) DNS协议: DNS协议(Domain Name Service, 域名服务)提供机器域名到IP地址的转换。如百度的机器域名是www.baidu.com，对应的IP地址是http://119.75.217.109/。
另外注意，ping是应用程序而非协议，它利用网络层的ICMP协议监测网络连接。
应用层协议可以跳过传输层直接使用网络层提供的服务，比如ping程序和OSPF协议；又可以既使用TCP服务，又可以使用UDP服务，如DNS协议。

#5.ICMP 报文种类以及作用；和 IP 数据报的关系；Ping 和 Traceroute 的具体原理。
IP协议并不是一个可靠的协议，它不保证数据被送达，那么，自然的，保证数据送达的工作应该由其他的模块来完成。其中一个重要的模块就是ICMP(网络控制报文)协议。
当传送IP数据包发生错误－－比如主机不可达，路由不可达等等，ICMP协议将会把错误信息封包，然后传送回给主机。给主机一个处理错误的机会，这也就是为什么说建立在IP层以上的协议是可能做到安全的原因。ICMP数据包由8bit的错误类型和8bit的代码和16bit的校验和组成。而前 16bit就组成了ICMP所要传递的信息。
ICMP协议大致分为两类，一种是查询报文，一种是差错报文。其中查询报文有以下几种用途:

ping查询  
ping 程序是用来探测主机到主机之间是否可通信，如果不能ping到某台主机，表明不能和这台主机建立连接。ping 使用的是ICMP协议，它发送icmp回送请求消息给目的主机。ICMP协议规定：目的主机必须返回ICMP回送应答消息给源主机。如果源主机在一定时间内收到应答，则认为主机可达。
假定主机A的IP地址是192.168.1.1，主机B的IP地址是192.168.1.2，都在同一子网内，则当你在主机A上运行“Ping 192.168.1.2”后，都发生了些什么呢?
首先，Ping命令会构建一个固定格式的ICMP请求数据包，然后由ICMP协议将这个数据包连同地址“192.168.1.2”一起交给IP层协议（和ICMP一样，实际上是一组后台运行的进程），IP层协议将以地址“192.168.1.2”作为目的地址，本机IP地址作为源地址，加上一些其他的控制信息，构建一个IP数据包，并在一个映射表中查找出IP地址192.168.1.2所对应的物理地址，一并交给数据链路层。其中, 映射表由ARP实现。ARP(Address Resolution Protocol)是地址解析协议,是一种将IP地址转化成物理地址的协议。后者构建一个数据帧，目的地址是IP层传过来的物理地址，源地址则是本机的物理地址，还要附加上一些控制信息，依据以太网的介质访问规则，将它们传送出去。
主机B收到这个数据帧后，先检查它的目的地址，并和本机的物理地址对比，如符合，则接收；否则丢弃。接收后检查该数据帧，将IP数据包从帧中提取出来，交给本机的IP层协议。同样，IP层检查后，将有用的信息提取后交给ICMP协议，后者处理后，马上构建一个ICMP应答包，发送给主机A，其过程和主机A发送ICMP请求包到主机B一模一样。

Traceroute是用来侦测主机到目的主机之间所经路由情况的重要工具  
尽管ping工具也可以进行侦测，但是，因为ip头的限制，ping不能完全的记录下所经过的路由器。Traceroute的原理是非常非常的有意思，它受到目的主机的IP后，首先给目的主机发送一个TTL=1（TTL 指定数据报被路由器丢弃之前允许通过的网段数量。）的UDP数据包，而经过的第一个路由器收到这个数据包以后，就自动把TTL减1，而TTL变为0以后，路由器就把这个包给抛弃了，并同时产生 一个主机不可达的ICMP数据报给主机。主机收到这个数据报以后再发一个TTL=2的UDP数据报给目的主机，然后刺激第二个路由器给主机发ICMP数据报。如此往复直到到达目的主机。这样，traceroute就拿到了所有的路由器ip。从而避开了ip头只能记录有限路由IP的问题。

#6.UDP 与 TCP 比较，分析上层协议应该使用 UDP 还是 TCP。
1、TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接.  
2、TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付。
Tcp通过校验和，重传控制，序号标识，滑动窗口、确认应答实现可靠传输。如丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。  
3、UDP具有较好的实时性，工作效率比TCP高，适用于对高速传输和实时性有较高的通信或广播通信。  
4.每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信  
5、TCP对系统资源要求较多，UDP对系统资源要求较少。

####6.1滑动窗口
![](figure/huadongwindow.jpg)
对于发送端来说，即将要发送的数据包排成一个队列，对于发送者来说，数据包总共分成四类。分别是在窗口前的，已经发送给接收方，并且收到了接收方的答复，我们称之为已发送。在窗口中的，有两种状态，一个是已经发送给接收方，但是接收方还没确认送达，我们称之为已发送未确认，另外一个是可以发送了，但是还没有发送，我们称之为允许发送未发送。最后的是在窗口外面的，我们称之为不可发送，除非窗口滑到此处，否则不会进行发送。
TCP的滑动窗口协议有什么意义呢？首先当然是可靠性，滑动窗口只有在队列前部的被确认之后，才会往后移动，保证数据包被接收方确认并接收。滑动窗口还可控制接收以及同步数据范围的，通知发送端目前接收的数据范围，用于流量控制

滑动窗口实现了TCP流控制。首先明确滑动窗口的范畴：TCP是双工的协议，会话的双方都可以同时接收和发送数据。TCP会话的双方都各自维护一个发送窗口和一个接收窗口。各自的接收窗口大小取决于应用、系统、硬件的限制（TCP传输速率不能大于应用的数据处理速率）。各自的发送窗口则要求取决于对端通告的接收窗口，要求相同。
滑动窗口解决的是流量控制的的问题，就是如果接收端和发送端对数据包的处理速度不同，如何让双方达成一致。接收端的缓存传输数据给应用层，但这个过程不一定是即时的，如果发送速度太快，会出现接收端数据overflow，流量控制解决的是这个问题。

Tpis: 对比滑动窗口和拥塞窗口
滑动窗口是控制接收以及同步数据范围的，通知发送端目前接收的数据范围，用于流量控制，接收端使用。拥塞窗口是控制发送速率的，避免发的过多，发送端使用。因为tcp是全双工，所以两边都有滑动窗口。
两个窗口的维护是独立的，滑动窗口主要由接收方反馈缓存情况来维护，拥塞窗口主要由发送方的拥塞控制算法检测出的网络拥塞程度来决定的。
发送方取拥塞窗口与滑动窗口中的最小值作为发送上限。拥塞窗口是发送方使用的流量控制，而滑动窗口则是接收方使用的流量控制。
拥塞窗口控制sender向connection传输数据的速率，使这个速率为网络拥堵状况的函数。

####6.2拥塞控制
慢启动、拥塞避免、快重传
![](figure/yongsecontrol.png)
![](figure/yongsecontrol2.png)
第二图是快恢复，收到3个相同的ack，把阈值缩小为一半，窗口不再慢开始，而是从阈值开始。快重传：收到3个相同的ack，立刻重传ack序号的下一个，然后启动快恢复。

作用：拥塞控制就是为了防止过多的数据注入到网络中，这样可以使网络中的路由器或者链路不至于过载。拥塞控制要做的都有一个前提：就是网络能够承受现有的网络负荷.
慢启动，拥塞窗口初始为1，指数增长。拥塞避免，超过阈值，开始线性增长，造成拥塞，乘法减小，窗口值变为1，阈值为当前的1/2.  细节如上。
快重传：快重传算法要求首先接收方收到一个失序的报文段后就立刻发出重复确认，而不要等待自己发送数据时才进行捎带确认。接收方成功的接受了发送方发送来的M1、M2并且分别给发送了ACK，现在接收方没有收到M3，而接收到了M4，显然接收方不能确认M4，因为M4是失序的报文段。如果根据可靠性传输原理接收方什么都不做，但是按照快速重传算法，在收到M4、M5等报文段的时候，不断重复的向发送方发送M2的ACK,如果接收方一连收到三个重复的ACK,那么发送方不必等待重传计时器到期，由于发送方尽早重传未被确认的报文段。
![](figure/kuaichongchuan.png)

#7.DNS过程
53端口号。DNS更多情况下使用UDP, 这样DNS服务器负载更低，响应更快。
当一个用户在地址栏输入www.taobao.com时，DNS解析有大致十个过程，如下：  
（1）	浏览器先检查自身缓存中有没有被解析过的这个域名对应的ip地址，如果有，解析结束。同时域名被缓存的时间也可通过TTL属性来设置。  
（2）	如果浏览器缓存中没有（专业点叫还没命中），浏览器会检查操作系统缓存中有没有对应的已解析过的结果。而操作系统也有一个域名解析的过程。在windows中可通过c盘里一个叫hosts的文件来设置，如果你在这里指定了一个域名对应的ip地址，那浏览器会首先使用这个ip地址。  
（3）	如果至此还没有命中域名，才会真正的请求本地域名服务器（LDNS）来解析这个域名，这台服务器一般在你的城市的某个角落，距离你不会很远，并且这台服务器的性能都很好，一般都会缓存域名解析结果，大约80%的域名解析到这里就完成了。  
（4）	如果LDNS仍然没有命中，就直接跳到Root Server 域名服务器请求解析  
（5）	根域名服务器返回给LDNS一个所查询域的主域名服务器（gTLD Server，国际顶尖域名服务器，如.com .cn .org等）地址  
（6）	此时LDNS再发送请求给上一步返回的gTLD  
（7）	接受请求的gTLD查找并返回这个域名对应的Name Server的地址，这个Name Server就是网站注册的域名服务器  
（8）	Name Server根据映射关系表找到目标ip，返回给LDNS  
（9）	LDNS缓存这个域名和对应的ip   
（10）	LDNS把解析的结果返回给用户，用户根据TTL值缓存到本地系统缓存中，域名解析过程至此结束
####7.1	浏览器输入一个url至显示主页之后的过程，用到的协议？
DNS解析返回IP：PORT，请求简历TCP连接，通过网络层，链路层，...发送过去。 经过三次握手，简历好TCP连接，之后可通信。
#8.为什么UDP比TCP快
UDP比TCP快的地方UDP没有流量控制，拥塞控制，没有握手，没有成功确认，一个数据包发过去就不管。
#9.粘包，拆包及解决办法
1、要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包。  
2、待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。  
3、要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包。  
4、接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。
等等。

粘包、拆包解决办法  
通过以上分析，我们清楚了粘包或拆包发生的原因，那么如何解决这个问题呢？解决问题的关键在于如何给每个数据包添加边界信息，常用的方法有如下几个：  
1、发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。  
2、发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。  
3、可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。等等。

#10.Socket
Socket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket其实就是一个门面模式，它把复杂的TCP/IP协议族隐藏在Socket接口后面，对用户来说，一组简单的接口就是全部，让Socket去组织数据，以符合指定的协议。而我们所说的socket编程指的是利用socket接口来实现自己的业务和协议。
Socket是对TCP/IP协议的封装，Socket本身并不是协议，而是一个调用接口（API），通过Socket，我们才能使用TCP/IP协议。

建立Socket连接至少需要一对套接字，其中一个运行于客户端，称为ClientSocket ，另一个运行于服务器端，称为ServerSocket 。
套接字之间的连接过程分为三个步骤：服务器监听，客户端请求，连接确认。

#11.IO模型对比
![](figure/NIO.png)

![](figure/BIO.png)

![](figure/MIO.gif)
